# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hYsVrR8UjsN0_HVDjEHNXbzWLwkhA2tc
"""

import tensorflow as tf
from tensorflow import keras
from keras.applications import ResNet50
from keras.models import Sequential
from keras.layers import Dense, Flatten, GlobalAveragePooling2D
from keras.utils.data_utils import get_file
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.resnet50 import preprocess_input
from sklearn.metrics import confusion_matrix

from google.colab import drive
drive.mount('/gdrive')

datagen = ImageDataGenerator()
batch_size=32 #Hyperparameter1

train_it=datagen.flow_from_directory(directory='/gdrive/My Drive/Colab Notebooks/Data/Train',class_mode='categorical',batch_size=batch_size)
test_it=datagen.flow_from_directory(directory='/gdrive/My Drive/Colab Notebooks/Data/Test',class_mode='categorical',batch_size=batch_size)
predict_it=datagen.flow_from_directory(directory='/gdrive/My Drive/Colab Notebooks/Data/Predict',class_mode='categorical',batch_size=batch_size)
#print(train_it[0])
#print(test_it[0])
#print(predict_it[0][1])
xtrain=train_it[0][0]
ytrain=train_it[0][1]
xtest=train_it[0][0]
ytest=train_it[0][1]
xpredict=predict_it[0][0]
ypredict=predict_it[0][1]
class_names = ['advanced', 'mild', 'moderate', 'severe',]



#Resnetlayer = keras.applications.ResNet50(include_top=False, pooling='avg', weights=weights_path)
#Outputdenselayer = keras.layers.Dense(4,activation=tf.nn.softmax)#modelling to be done 
#model = keras.Sequential([Resnetlayer,Outputdenselayer])
model = Sequential()
model.add(ResNet50(include_top=False,pooling='avg',weights='imagenet'))
model.add(Dense(16, activation='relu'))
model.add(Dense(4, activation='softmax'))
model.layers[0].trainable = False
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])#hyperparameters2
#model.fit_generator(train_it, steps_per_epoch=16,verbose=1)#hyperparameters3
#loss = model.evaluate_generator(test_it,steps=24,verbose=1)
#prediction = model.predict_generator(predict_it,steps=24,verbose=1)

train_history = model.fit(xtrain,ytrain,epochs=25)

predictions=model.predict(xtest)



#print(np.argmax(predictions[i]))
#print(np.argmax(ytest[i]))
#ccount=0
#wcount=0
#for i in range(len(predictions)):
#    if np.argmax(predictions[i])== np.argmax(ytest[i]):
#        ccount+=1
#    else :
#        wcount+=1
#print(ccount)
#print(wcount)



